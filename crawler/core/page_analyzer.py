"""
é¡µé¢åˆ†æå™¨

åˆ†æé¡µé¢ç±»å‹ã€ç»“æ„å’Œç‰¹å¾
"""

import logging
import re
from typing import Dict, Optional

logger = logging.getLogger(__name__)


class PageAnalyzer:
    """é¡µé¢åˆ†æå™¨"""

    def __init__(self, config_manager):
        self.config_manager = config_manager

    def analyze_page(self, response, site_name: str) -> Dict:
        """åˆ†æé¡µé¢å¹¶è¿”å›åˆ†æç»“æœ"""
        analysis = {
            "url": response.url,
            "site_name": site_name,
            "page_type": self._detect_page_type(response, site_name),
            "content_features": self._analyze_content_features(response),
            "structure_info": self._analyze_page_structure(response),
        }

        logger.info(f"ğŸ“Š é¡µé¢åˆ†æå®Œæˆ: {analysis['page_type']} | {response.url}")
        return analysis

    def _detect_page_type(self, response, site_name: str) -> str:
        """æ£€æµ‹é¡µé¢ç±»å‹"""
        # è·å–æ£€æµ‹é…ç½®
        detection_config = self.config_manager.get_detection_config(site_name)

        if not detection_config:
            return self._generic_page_type_detection(response)

        # ä½¿ç”¨é…ç½®åŒ–æ£€æµ‹
        page_types = detection_config.get("page_types", {})

        for page_type, rules in page_types.items():
            if self._match_page_type_rules(response, rules):
                logger.debug(f"ğŸ” åŒ¹é…é¡µé¢ç±»å‹: {page_type}")
                return page_type

        # å›é€€åˆ°é€šç”¨æ£€æµ‹
        return self._generic_page_type_detection(response)

    def _match_page_type_rules(self, response, rules: Dict) -> bool:
        """åŒ¹é…é¡µé¢ç±»å‹è§„åˆ™"""
        try:
            # URLæ¨¡å¼åŒ¹é…
            url_patterns = rules.get("url_patterns", [])
            if url_patterns:
                url = response.url.lower()
                for pattern in url_patterns:
                    if re.search(pattern, url):
                        logger.debug(f"âœ… URLæ¨¡å¼åŒ¹é…: {pattern}")
                        return True

            # å†…å®¹ç‰¹å¾åŒ¹é…
            content_features = rules.get("content_features", {})
            if content_features:
                if self._match_content_features(response, content_features):
                    logger.debug("âœ… å†…å®¹ç‰¹å¾åŒ¹é…")
                    return True

            # ç»“æ„ç‰¹å¾åŒ¹é…
            structure_features = rules.get("structure_features", {})
            if structure_features:
                if self._match_structure_features(response, structure_features):
                    logger.debug("âœ… ç»“æ„ç‰¹å¾åŒ¹é…")
                    return True

            return False

        except Exception as e:
            logger.error(f"é¡µé¢ç±»å‹è§„åˆ™åŒ¹é…å¤±è´¥: {e}")
            return False

    def _match_content_features(self, response, features: Dict) -> bool:
        """åŒ¹é…å†…å®¹ç‰¹å¾"""
        # æ£€æŸ¥æœ€å°é“¾æ¥æ•°
        min_links = features.get("min_links", 0)
        if min_links > 0:
            links = response.css("a::attr(href)").getall()
            if len(links) < min_links:
                return False

        # æ£€æŸ¥å…³é”®è¯
        keywords = features.get("keywords", [])
        if keywords:
            text_content = response.text.lower()
            for keyword in keywords:
                if keyword.lower() not in text_content:
                    return False

        # æ£€æŸ¥æœ€å°å†…å®¹é•¿åº¦
        min_content_length = features.get("min_content_length", 0)
        if min_content_length > 0:
            if len(response.text) < min_content_length:
                return False

        return True

    def _match_structure_features(self, response, features: Dict) -> bool:
        """åŒ¹é…ç»“æ„ç‰¹å¾"""
        # æ£€æŸ¥å¿…éœ€çš„é€‰æ‹©å™¨
        required_selectors = features.get("required_selectors", [])
        for selector in required_selectors:
            # åˆ¤æ–­æ˜¯XPathè¿˜æ˜¯CSSé€‰æ‹©å™¨
            if selector.startswith("/") or selector.startswith("./"):
                # XPathé€‰æ‹©å™¨
                if not response.xpath(selector):
                    return False
            else:
                # CSSé€‰æ‹©å™¨
                if not response.css(selector):
                    return False

        # æ£€æŸ¥æœ€å°å…ƒç´ æ•°é‡
        min_elements = features.get("min_elements", {})
        for selector, min_count in min_elements.items():
            # åˆ¤æ–­æ˜¯XPathè¿˜æ˜¯CSSé€‰æ‹©å™¨
            if selector.startswith("/") or selector.startswith("./"):
                # XPathé€‰æ‹©å™¨
                elements = response.xpath(selector)
            else:
                # CSSé€‰æ‹©å™¨
                elements = response.css(selector)

            if len(elements) < min_count:
                return False

        return True

    def _generic_page_type_detection(self, response) -> str:
        """é€šç”¨é¡µé¢ç±»å‹æ£€æµ‹"""
        url = response.url.lower()

        # URLå…³é”®è¯æ£€æµ‹
        if any(keyword in url for keyword in ["list", "index", "category", "åˆ—è¡¨"]):
            if self._is_list_page_content(response):
                return "list_page"

        if any(keyword in url for keyword in ["detail", "article", "news", "è¯¦æƒ…", "æ–°é—»"]):
            if self._is_detail_page_content(response):
                return "detail_page"

        # å†…å®¹ç‰¹å¾æ£€æµ‹
        if self._is_list_page_content(response):
            return "list_page"
        elif self._is_detail_page_content(response):
            return "detail_page"

        return "unknown_page"

    def _is_list_page_content(self, response) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºåˆ—è¡¨é¡µå†…å®¹"""
        try:
            # æ£€æŸ¥é“¾æ¥æ•°é‡
            links = response.css("a::attr(href)").getall()
            if len(links) < 5:
                return False

            # æ£€æŸ¥åˆ—è¡¨ç»“æ„
            list_selectors = ["ul li a", "ol li a", ".list", '[class*="list"]']
            for selector in list_selectors:
                elements = response.css(selector)
                if len(elements) >= 3:
                    return True

            # æ£€æŸ¥æ—¥æœŸæ¨¡å¼
            date_patterns = response.css("*::text()").re(
                r"\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}[æ—¥]?"
            )
            if len(date_patterns) >= 3:
                return True

            return False

        except Exception:
            return False

    def _is_detail_page_content(self, response) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºè¯¦æƒ…é¡µå†…å®¹"""
        try:
            # æ£€æŸ¥è¯¦æƒ…é¡µç»“æ„
            detail_selectors = [
                "article",
                ".article",
                ".content",
                ".detail",
                '[class*="content"]',
            ]
            for selector in detail_selectors:
                elements = response.css(selector)
                if elements:
                    content_text = " ".join(elements.css("*::text()").getall())
                    if len(content_text) > 200:
                        return True

            # æ£€æŸ¥å†…å®¹é•¿åº¦
            all_text = " ".join(response.css("*::text()").getall())
            if len(all_text) > 1000:
                # æ£€æŸ¥æ ‡é¢˜
                title_selectors = ["h1", "h2", ".title", '[class*="title"]']
                for selector in title_selectors:
                    if response.css(selector):
                        return True

            return False

        except Exception:
            return False

    def _analyze_content_features(self, response) -> Dict:
        """åˆ†æå†…å®¹ç‰¹å¾"""
        try:
            text_content = response.text
            return {
                "total_length": len(text_content),
                "link_count": len(response.css("a::attr(href)").getall()),
                "image_count": len(response.css("img::attr(src)").getall()),
                "paragraph_count": len(response.css("p").getall()),
                "has_forms": bool(response.css("form")),
                "has_tables": bool(response.css("table")),
            }
        except Exception as e:
            logger.error(f"å†…å®¹ç‰¹å¾åˆ†æå¤±è´¥: {e}")
            return {}

    def _analyze_page_structure(self, response) -> Dict:
        """åˆ†æé¡µé¢ç»“æ„"""
        try:
            return {
                "has_navigation": bool(response.css("nav, .nav, .navigation")),
                "has_sidebar": bool(response.css(".sidebar, .side, aside")),
                "has_footer": bool(response.css("footer, .footer")),
                "has_header": bool(response.css("header, .header")),
                "main_content_selector": self._find_main_content_selector(response),
            }
        except Exception as e:
            logger.error(f"é¡µé¢ç»“æ„åˆ†æå¤±è´¥: {e}")
            return {}

    def _find_main_content_selector(self, response) -> Optional[str]:
        """æŸ¥æ‰¾ä¸»è¦å†…å®¹é€‰æ‹©å™¨"""
        main_selectors = [
            "main",
            ".main",
            "#main",
            ".content",
            "#content",
            ".container",
            "#container",
            "article",
            ".article",
        ]

        for selector in main_selectors:
            if response.css(selector):
                return selector

        return None
