# ğŸ›¡ï¸ ç¬¬äºŒé˜¶æ®µä½¿ç”¨æŒ‡å— - åçˆ¬æœºåˆ¶åº”å¯¹

**ç‰ˆæœ¬**: v2.0
**æ›´æ–°æ—¶é—´**: 2025å¹´8æœˆ3æ—¥
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨Selenium Grid

```bash
# å¯åŠ¨Selenium GridæœåŠ¡
docker-compose -f deployment/docker/docker-compose.yml --profile selenium up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose -f deployment/docker/docker-compose.yml ps

# éªŒè¯GridçŠ¶æ€
curl http://localhost:4444/wd/hub/status
```

### 2. æµ‹è¯•ç³»ç»ŸåŠŸèƒ½

```bash
# è¿è¡ŒåŠŸèƒ½éªŒè¯æµ‹è¯•
uv run python test_phase2_final.py

# è¿è¡Œæ·±åº¦è°ƒè¯•æµ‹è¯•
uv run python debug_phase2.py

# æµ‹è¯•Selenium Grid
uv run python test_selenium_grid.py
```

### 3. ä½¿ç”¨åçˆ¬è™«åŠŸèƒ½

```bash
# å¯ç”¨åçˆ¬è™«æ£€æµ‹
uv run scrapy crawl adaptive -a site=test_site -s ANTI_CRAWL_ENABLED=True

# å¯ç”¨Seleniumæ”¯æŒ
uv run scrapy crawl adaptive -a site=test_site -s SELENIUM_ENABLED=True

# å¯ç”¨è¡Œä¸ºæ¨¡æ‹Ÿ
uv run scrapy crawl adaptive -a site=test_site -s BEHAVIOR_MIN_DELAY=2.0

# ç»¼åˆä½¿ç”¨æ‰€æœ‰åŠŸèƒ½
uv run scrapy crawl adaptive -a site=test_site \
  -s ANTI_CRAWL_ENABLED=True \
  -s SELENIUM_ENABLED=True \
  -s BEHAVIOR_MIN_DELAY=1.0 \
  -s BEHAVIOR_MAX_DELAY=3.0
```

---

## âš™ï¸ é…ç½®é€‰é¡¹

### Seleniumé…ç½®

```python
# Selenium Gridé…ç½®
SELENIUM_ENABLED = False  # æ˜¯å¦å¯ç”¨Selenium
SELENIUM_GRID_URL = 'http://localhost:4444'  # Gridåœ°å€
SELENIUM_BROWSER = 'chrome'  # æµè§ˆå™¨ç±»å‹: chrome/firefox
SELENIUM_IMPLICIT_WAIT = 10  # éšå¼ç­‰å¾…æ—¶é—´
SELENIUM_PAGE_LOAD_TIMEOUT = 30  # é¡µé¢åŠ è½½è¶…æ—¶
SELENIUM_WINDOW_SIZE = (1920, 1080)  # æµè§ˆå™¨çª—å£å¤§å°
```

### åçˆ¬è™«æ£€æµ‹é…ç½®

```python
# åçˆ¬è™«æ£€æµ‹é…ç½®
ANTI_CRAWL_ENABLED = True  # æ˜¯å¦å¯ç”¨åçˆ¬è™«æ£€æµ‹
ANTI_CRAWL_AUTO_RETRY = True  # æ˜¯å¦è‡ªåŠ¨é‡è¯•
ANTI_CRAWL_MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
ANTI_CRAWL_RETRY_DELAY = 5  # é‡è¯•å»¶è¿Ÿ(ç§’)
```

### è¡Œä¸ºæ¨¡æ‹Ÿé…ç½®

```python
# è¡Œä¸ºæ¨¡æ‹Ÿé…ç½®
BEHAVIOR_MIN_DELAY = 1.0  # æœ€å°å»¶è¿Ÿ(ç§’)
BEHAVIOR_MAX_DELAY = 5.0  # æœ€å¤§å»¶è¿Ÿ(ç§’)
```

### éªŒè¯ç è¯†åˆ«é…ç½®

```python
# éªŒè¯ç è¯†åˆ«é…ç½®
CAPTCHA_SERVICE_URL = None  # ç¬¬ä¸‰æ–¹éªŒè¯ç è¯†åˆ«æœåŠ¡URL
```

---

## ğŸ›¡ï¸ åçˆ¬è™«æœºåˆ¶æ£€æµ‹

### æ”¯æŒçš„æ£€æµ‹ç±»å‹

1. **éªŒè¯ç æ£€æµ‹** - è¯†åˆ«å„ç§éªŒè¯ç ç±»å‹
2. **JavaScriptæŒ‘æˆ˜** - æ£€æµ‹JSåçˆ¬è™«ä»£ç 
3. **é¢‘ç‡é™åˆ¶** - è¯†åˆ«è¯·æ±‚é¢‘ç‡æ§åˆ¶
4. **IPå°ç¦** - æ£€æµ‹IPé»‘åå•
5. **User-Agentæ£€æŸ¥** - è¯†åˆ«æµè§ˆå™¨æ£€æµ‹
6. **Cookieæ£€æŸ¥** - æ£€æµ‹ä¼šè¯è¦æ±‚
7. **Refereræ£€æŸ¥** - è¯†åˆ«æ¥æºéªŒè¯
8. **æµè§ˆå™¨æŒ‡çº¹** - æ£€æµ‹æŒ‡çº¹è¯†åˆ«
9. **èœœç½é™·é˜±** - è¯†åˆ«éšè—é“¾æ¥
10. **è¡Œä¸ºåˆ†æ** - æ£€æµ‹è¡Œä¸ºæ¨¡å¼åˆ†æ

### æ£€æµ‹ç»“æœç¤ºä¾‹

```python
{
    'detected': ['captcha', 'rate_limit'],
    'confidence': {'captcha': 0.9, 'rate_limit': 0.8},
    'suggestions': [
        'ä½¿ç”¨OCRè¯†åˆ«éªŒè¯ç ',
        'å¢åŠ è¯·æ±‚é—´éš”',
        'ä½¿ç”¨ä»£ç†æ± è½®æ¢IP'
    ]
}
```

---

## ğŸ•·ï¸ Seleniumé›†æˆ

### è‡ªåŠ¨æ£€æµ‹è§„åˆ™

ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ä»¥ä¸‹æƒ…å†µå¹¶ä½¿ç”¨Seleniumï¼š

1. **è¯·æ±‚å…ƒæ•°æ®æ ‡è®°**: `request.meta['selenium'] = True`
2. **JavaScripté‡å®šå‘**: æ£€æµ‹åˆ°JSè·³è½¬ä»£ç 
3. **ç‰¹å®šURLæ¨¡å¼**: åŒ…å«`javascript:`æˆ–`#`çš„URL
4. **ç‰¹å®šåŸŸå**: é…ç½®çš„éœ€è¦JSæ¸²æŸ“çš„ç½‘ç«™

### æ‰‹åŠ¨æŒ‡å®šSelenium

```python
from crawler.selenium_middleware import SeleniumRequest

# åˆ›å»ºSeleniumè¯·æ±‚
request = SeleniumRequest.create_request(
    url='http://example.com',
    wait_time=3,  # ç­‰å¾…æ—¶é—´
    wait_element='#content',  # ç­‰å¾…ç‰¹å®šå…ƒç´ 
    custom_js='window.scrollTo(0, document.body.scrollHeight);'  # è‡ªå®šä¹‰JS
)
```

### Seleniumé…ç½®ç¤ºä¾‹

```python
# åœ¨çˆ¬è™«ä¸­ä½¿ç”¨
def parse(self, response):
    # æ ‡è®°éœ€è¦ä½¿ç”¨Selenium
    yield Request(
        url=next_url,
        callback=self.parse_detail,
        meta={
            'selenium': True,
            'selenium_wait': 5,
            'selenium_wait_element': '.content',
            'selenium_js': 'document.querySelector("#load-more").click();'
        }
    )
```

---

## ğŸŒ é«˜çº§ä»£ç†æ± 

### ä»£ç†è´¨é‡è¯„åˆ†

ç³»ç»ŸåŸºäºä»¥ä¸‹ç»´åº¦è¯„ä¼°ä»£ç†è´¨é‡ï¼š

- **æˆåŠŸç‡** (æƒé‡: 30%)
- **å“åº”æ—¶é—´** (æƒé‡: 20%)
- **è¿ç»­å¤±è´¥æ¬¡æ•°** (æ‰£åˆ†é¡¹)
- **ä½¿ç”¨é¢‘ç‡** (å¹³è¡¡è´Ÿè½½)

### ä»£ç†ç­›é€‰æ¡ä»¶

```python
# è·å–æœ€ä½³ä»£ç†
criteria = {
    'location': 'US',  # åœ°ç†ä½ç½®
    'type': 'residential',  # ä»£ç†ç±»å‹
    'min_score': 0.7,  # æœ€å°è¯„åˆ†
    'max_failures': 3  # æœ€å¤§å¤±è´¥æ¬¡æ•°
}

proxy = manager.get_best_proxy(criteria)
```

### ä»£ç†ç»Ÿè®¡ä¿¡æ¯

```python
stats = manager.get_proxy_statistics()
# è¿”å›:
{
    'total_proxies': 100,
    'active_proxies': 85,
    'failed_proxies': 15,
    'average_score': 0.75,
    'type_distribution': {
        'datacenter': 60,
        'residential': 25,
        'mobile': 15
    },
    'locations': 12
}
```

---

## ğŸ­ è¡Œä¸ºæ¨¡æ‹Ÿ

### å»¶è¿Ÿæ§åˆ¶

```python
# é…ç½®éšæœºå»¶è¿Ÿ
BEHAVIOR_MIN_DELAY = 2.0  # æœ€å°2ç§’
BEHAVIOR_MAX_DELAY = 5.0  # æœ€å¤§5ç§’

# å®é™…å»¶è¿Ÿä¼šåœ¨æ­¤èŒƒå›´å†…éšæœºé€‰æ‹©
```

### è¯·æ±‚å¤´è½®æ¢

ç³»ç»Ÿä¼šè‡ªåŠ¨è½®æ¢ä»¥ä¸‹è¯·æ±‚å¤´ï¼š

- **User-Agent**: æ¨¡æ‹Ÿä¸åŒæµè§ˆå™¨
- **Accept**: ä¸åŒçš„å†…å®¹ç±»å‹åå¥½
- **Accept-Language**: ä¸åŒçš„è¯­è¨€åå¥½
- **Accept-Encoding**: ä¸åŒçš„ç¼–ç æ”¯æŒ
- **Connection**: è¿æ¥ç±»å‹
- **Cache-Control**: ç¼“å­˜æ§åˆ¶

### ä¼šè¯ä¿æŒ

```python
# å¯ç”¨Cookieæ”¯æŒ
request.meta['cookiejar'] = 'session_name'

# è®¾ç½®Referer
request.headers['Referer'] = 'https://example.com/'
```

---

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### æ—¥å¿—ç›‘æ§

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f logs/scrapy.log

# æœç´¢åçˆ¬è™«ç›¸å…³æ—¥å¿—
grep -i "anti_crawl\|412\|captcha\|selenium" logs/scrapy.log
```

### æ€§èƒ½ç›‘æ§

```bash
# æ£€æŸ¥Selenium GridçŠ¶æ€
curl http://localhost:4444/wd/hub/status | jq

# æŸ¥çœ‹Dockerå®¹å™¨çŠ¶æ€
docker-compose -f deployment/docker/docker-compose.yml ps

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs crawler_selenium_hub
docker logs crawler_chrome_node
```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
uv run scrapy crawl adaptive -a site=test_site \
  -s LOG_LEVEL=DEBUG \
  -s ANTI_CRAWL_ENABLED=True

# åªå¯ç”¨ç‰¹å®šä¸­é—´ä»¶
uv run scrapy crawl adaptive -a site=test_site \
  -s DOWNLOADER_MIDDLEWARES='{"anti_crawl.middleware.AntiCrawlMiddleware": 590}'
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. Selenium Gridè¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose -f deployment/docker/docker-compose.yml ps

# é‡å¯æœåŠ¡
docker-compose -f deployment/docker/docker-compose.yml restart selenium-hub

# æŸ¥çœ‹æ—¥å¿—
docker logs crawler_selenium_hub
```

#### 2. åçˆ¬è™«æ£€æµ‹ä¸å·¥ä½œ

```bash
# éªŒè¯æ¨¡å—å¯¼å…¥
python -c "from anti_crawl.detector import AntiCrawlDetector; print('OK')"

# æ£€æŸ¥é…ç½®
python -c "from crawler.settings import ANTI_CRAWL_ENABLED; print(ANTI_CRAWL_ENABLED)"
```

#### 3. ä¸­é—´ä»¶åŠ è½½å¤±è´¥

```bash
# éªŒè¯ä¸­é—´ä»¶
python -c "import crawler.middlewares; print('OK')"

# æ£€æŸ¥é…ç½®è¯­æ³•
python -c "from crawler.settings import DOWNLOADER_MIDDLEWARES"
```

### æ€§èƒ½ä¼˜åŒ–

#### 1. Selenium Gridä¼˜åŒ–

```yaml
# å¢åŠ èŠ‚ç‚¹æ•°é‡
chrome-node:
  scale: 3  # å¯åŠ¨3ä¸ªChromeèŠ‚ç‚¹

# è°ƒæ•´ä¼šè¯æ•°
environment:
  NODE_MAX_INSTANCES: 4
  NODE_MAX_SESSION: 4
```

#### 2. è¯·æ±‚é¢‘ç‡ä¼˜åŒ–

```python
# é™ä½å¹¶å‘æ•°
CONCURRENT_REQUESTS = 1
CONCURRENT_REQUESTS_PER_DOMAIN = 1

# å¢åŠ å»¶è¿Ÿ
DOWNLOAD_DELAY = 3
RANDOMIZE_DOWNLOAD_DELAY = 0.5
```

---

## ğŸ“ˆ æœ€ä½³å®è·µ

### 1. æ¸è¿›å¼å¯ç”¨åŠŸèƒ½

```bash
# ç¬¬ä¸€æ­¥ï¼šåŸºç¡€çˆ¬è™«
uv run scrapy crawl adaptive -a site=target_site

# ç¬¬äºŒæ­¥ï¼šå¯ç”¨åçˆ¬è™«æ£€æµ‹
uv run scrapy crawl adaptive -a site=target_site -s ANTI_CRAWL_ENABLED=True

# ç¬¬ä¸‰æ­¥ï¼šå¯ç”¨è¡Œä¸ºæ¨¡æ‹Ÿ
uv run scrapy crawl adaptive -a site=target_site \
  -s ANTI_CRAWL_ENABLED=True \
  -s BEHAVIOR_MIN_DELAY=2.0

# ç¬¬å››æ­¥ï¼šå¯ç”¨Seleniumï¼ˆå¦‚éœ€è¦ï¼‰
uv run scrapy crawl adaptive -a site=target_site \
  -s ANTI_CRAWL_ENABLED=True \
  -s BEHAVIOR_MIN_DELAY=2.0 \
  -s SELENIUM_ENABLED=True
```

### 2. ç›‘æ§å’Œè°ƒä¼˜

- **ç›‘æ§æˆåŠŸç‡**: å…³æ³¨çˆ¬å–æˆåŠŸç‡å˜åŒ–
- **åˆ†ææ—¥å¿—**: å®šæœŸæ£€æŸ¥åçˆ¬è™«æ£€æµ‹æ—¥å¿—
- **è°ƒæ•´å‚æ•°**: æ ¹æ®ç½‘ç«™ç‰¹ç‚¹è°ƒæ•´å»¶è¿Ÿå’Œé‡è¯•å‚æ•°
- **æ›´æ–°è§„åˆ™**: å®šæœŸæ›´æ–°åçˆ¬è™«æ£€æµ‹è§„åˆ™

### 3. å®‰å…¨è€ƒè™‘

- **éµå®ˆrobots.txt**: å°Šé‡ç½‘ç«™çš„çˆ¬å–è§„åˆ™
- **æ§åˆ¶é¢‘ç‡**: é¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè¿‡å¤§å‹åŠ›
- **ä½¿ç”¨ä»£ç†**: ä¿æŠ¤çœŸå®IPåœ°å€
- **æ•°æ®åˆè§„**: ç¡®ä¿æ•°æ®ä½¿ç”¨ç¬¦åˆæ³•å¾‹æ³•è§„

---

**ğŸ‰ ç¬¬äºŒé˜¶æ®µåçˆ¬è™«ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼å¼€å§‹æ‚¨çš„é«˜çº§çˆ¬è™«ä¹‹æ—…å§ï¼**
