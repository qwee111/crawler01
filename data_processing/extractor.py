# -*- coding: utf-8 -*-
"""
é…ç½®åŒ–æ•°æ®æå–å¼•æ“

æ”¯æŒå¤šç§æå–æ–¹æ³•ï¼šXPathã€CSSé€‰æ‹©å™¨ã€æ­£åˆ™è¡¨è¾¾å¼ã€JSONè·¯å¾„
"""

import json
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import yaml

try:
    from lxml import etree, html

    LXML_AVAILABLE = True
except ImportError:
    LXML_AVAILABLE = False

try:
    from bs4 import BeautifulSoup

    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    import jsonpath_ng

    JSONPATH_AVAILABLE = True
except ImportError:
    JSONPATH_AVAILABLE = False

try:
    from dateutil import parser as date_parser

    DATEUTIL_AVAILABLE = True
except ImportError:
    DATEUTIL_AVAILABLE = False

logger = logging.getLogger(__name__)


class ConfigurableExtractor:
    """é…ç½®åŒ–æ•°æ®æå–å™¨"""

    def __init__(self, config_path: Optional[str] = None):
        self.config = {}
        if config_path:
            self.load_config(config_path)

        # æ³¨å†Œæå–æ–¹æ³•
        self.extractors = {
            "xpath": self.extract_by_xpath,
            "css": self.extract_by_css,
            "regex": self.extract_by_regex,
            "json": self.extract_by_json,
            "jsonpath": self.extract_by_jsonpath,
            "text": self.extract_by_text,
        }

        logger.info("é…ç½®åŒ–æ•°æ®æå–å™¨åˆå§‹åŒ–å®Œæˆ")

    def load_config(self, config_path: str) -> Dict:
        """åŠ è½½æå–é…ç½®"""
        config_file = Path(config_path)

        if not config_file.exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return {}

        try:
            with open(config_file, "r", encoding="utf-8") as f:
                if config_file.suffix.lower() in [".yaml", ".yml"]:
                    self.config = yaml.safe_load(f)
                elif config_file.suffix.lower() == ".json":
                    self.config = json.load(f)
                else:
                    logger.error(f"ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: {config_file.suffix}")
                    return {}

            logger.info(f"é…ç½®åŠ è½½æˆåŠŸ: {config_path}")
            return self.config

        except Exception as e:
            logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
            return {}

    def extract_data(self, response, site_name: str) -> Dict[str, Any]:
        """æ ¹æ®é…ç½®æå–æ•°æ®"""
        if not self.config:
            logger.warning("æœªåŠ è½½é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æå–")
            return self._default_extract(response)

        site_config = self.config.get(site_name, {})
        if not site_config:
            logger.warning(f"æœªæ‰¾åˆ°ç½‘ç«™é…ç½®: {site_name}")
            return self._default_extract(response)

        extracted_data = {
            "url": response.url,
            "status_code": response.status,
            "extraction_time": self._get_current_time(),
            "site_name": site_name,
        }

        # æå–é…ç½®çš„å­—æ®µ
        fields_config = site_config.get("fields", {})
        for field_name, field_config in fields_config.items():
            try:
                value = self.extract_field(response, field_config)
                extracted_data[field_name] = self.clean_value(value, field_config)
                logger.debug(f"æå–å­—æ®µ {field_name}: {type(value)} - {str(value)[:100]}")

            except Exception as e:
                logger.error(f"æå–å­—æ®µ {field_name} å¤±è´¥: {e}")
                extracted_data[field_name] = None

        # æå–å…ƒæ•°æ®
        metadata = self._extract_metadata(response, site_config)
        extracted_data.update(metadata)

        return extracted_data

    def extract_field(self, response, field_config: Dict) -> Any:
        """æå–å•ä¸ªå­—æ®µ"""
        method = field_config.get("method", "xpath")
        selector = field_config.get("selector")

        if not selector:
            logger.warning(f"å­—æ®µé…ç½®ç¼ºå°‘selector: {field_config}")
            return None

        if method not in self.extractors:
            logger.error(f"ä¸æ”¯æŒçš„æå–æ–¹æ³•: {method}")
            return None

        try:
            return self.extractors[method](response, selector, field_config)
        except Exception as e:
            logger.error(f"æå–æ–¹æ³• {method} æ‰§è¡Œå¤±è´¥: {e}")
            return None

    def extract_by_xpath(
        self, response, selector: str, config: Dict
    ) -> Union[str, List[str], None]:
        """XPathæå–"""
        if not LXML_AVAILABLE:
            logger.error("lxmlåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨XPathæå–")
            return None

        try:
            # å®‰å…¨è·å–å†…å®¹
            content = self._get_response_content(response)
            if not content:
                logger.warning("æ— æ³•è·å–å“åº”å†…å®¹")
                return None

            tree = html.fromstring(content)
            elements = tree.xpath(selector)

            if config.get("multiple", False):
                results = []
                for elem in elements:
                    if hasattr(elem, "text_content"):
                        results.append(elem.text_content().strip())
                    elif hasattr(elem, "text"):
                        results.append(elem.text.strip() if elem.text else "")
                    else:
                        results.append(str(elem).strip())
                return results
            else:
                if elements:
                    elem = elements[0]
                    if hasattr(elem, "text_content"):
                        return elem.text_content().strip()
                    elif hasattr(elem, "text"):
                        return elem.text.strip() if elem.text else ""
                    else:
                        return str(elem).strip()
                return None

        except Exception as e:
            logger.error(f"XPathæå–å¤±è´¥: {e}")
            return None

    def extract_by_css(
        self, response, selector: str, config: Dict
    ) -> Union[str, List[str], None]:
        """CSSé€‰æ‹©å™¨æå–"""
        if not BS4_AVAILABLE:
            logger.error("BeautifulSoupåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨CSSé€‰æ‹©å™¨")
            return None

        try:
            content = self._get_response_content(response)
            if not content:
                logger.warning("æ— æ³•è·å–å“åº”å†…å®¹")
                return None

            soup = BeautifulSoup(content, "html.parser")
            elements = soup.select(selector)

            if config.get("multiple", False):
                return [elem.get_text().strip() for elem in elements]
            else:
                return elements[0].get_text().strip() if elements else None

        except Exception as e:
            logger.error(f"CSSé€‰æ‹©å™¨æå–å¤±è´¥: {e}")
            return None

    def extract_by_regex(
        self, response, pattern: str, config: Dict
    ) -> Union[str, List[str], None]:
        """æ­£åˆ™è¡¨è¾¾å¼æå–"""
        try:
            content = self._get_response_content(response)
            if not content:
                logger.warning("æ— æ³•è·å–å“åº”å†…å®¹")
                return None

            flags = re.DOTALL
            if config.get("ignorecase", False):
                flags |= re.IGNORECASE

            matches = re.findall(pattern, content, flags)

            if config.get("multiple", False):
                return matches
            else:
                return matches[0] if matches else None

        except Exception as e:
            logger.error(f"æ­£åˆ™è¡¨è¾¾å¼æå–å¤±è´¥: {e}")
            return None

    def extract_by_json(
        self, response, selector: str, config: Dict
    ) -> Union[str, List[str], None]:
        """JSONæå–"""
        try:
            content = self._get_response_content(response)
            if not content:
                return None

            data = json.loads(content)

            # ç®€å•çš„JSONè·¯å¾„æå–
            keys = selector.split(".")
            current = data

            for key in keys:
                if isinstance(current, dict) and key in current:
                    current = current[key]
                else:
                    return None

            return current

        except Exception as e:
            logger.error(f"JSONæå–å¤±è´¥: {e}")
            return None

    def extract_by_jsonpath(
        self, response, selector: str, config: Dict
    ) -> Union[str, List[str], None]:
        """JSONPathæå–"""
        if not JSONPATH_AVAILABLE:
            logger.error("jsonpath_ngåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨JSONPathæå–")
            return None

        try:
            content = self._get_response_content(response)
            if not content:
                return None

            data = json.loads(content)
            jsonpath_expr = jsonpath_ng.parse(selector)
            matches = [match.value for match in jsonpath_expr.find(data)]

            if config.get("multiple", False):
                return matches
            else:
                return matches[0] if matches else None

        except Exception as e:
            logger.error(f"JSONPathæå–å¤±è´¥: {e}")
            return None

    def extract_by_text(self, response, pattern: str, config: Dict) -> str:
        """çº¯æ–‡æœ¬æå–"""
        try:
            content = self._get_response_content(response)
            if not content:
                return None

            # ç§»é™¤HTMLæ ‡ç­¾
            if BS4_AVAILABLE:
                soup = BeautifulSoup(content, "html.parser")
                content = soup.get_text()

            # æ¸…ç†æ–‡æœ¬
            content = re.sub(r"\s+", " ", content).strip()

            return content

        except Exception as e:
            logger.error(f"çº¯æ–‡æœ¬æå–å¤±è´¥: {e}")
            return None

    def clean_value(self, value: Any, config: Dict) -> Any:
        """æ¸…æ´—æå–çš„å€¼"""
        if value is None:
            return None

        value_type = config.get("type", "string")

        try:
            if value_type == "string":
                if isinstance(value, list):
                    value = " ".join(str(v) for v in value)
                return str(value).strip()

            elif value_type == "integer":
                if isinstance(value, str):
                    # æå–æ•°å­—
                    numbers = re.findall(r"\d+", value)
                    return int(numbers[0]) if numbers else 0
                return int(value)

            elif value_type == "float":
                if isinstance(value, str):
                    numbers = re.findall(r"\d+\.?\d*", value)
                    return float(numbers[0]) if numbers else 0.0
                return float(value)

            elif value_type == "date":
                if DATEUTIL_AVAILABLE and isinstance(value, str):
                    return date_parser.parse(value).isoformat()
                return str(value)

            elif value_type == "list":
                if not isinstance(value, list):
                    return [value]
                return value

            else:
                return value

        except Exception as e:
            logger.error(f"å€¼æ¸…æ´—å¤±è´¥: {e}")
            return value

    def parse_date(self, date_str: str) -> Optional[str]:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²"""
        if not DATEUTIL_AVAILABLE:
            logger.warning("dateutilåº“æœªå®‰è£…ï¼Œæ— æ³•è§£ææ—¥æœŸ")
            return str(date_str)

        try:
            parsed_date = date_parser.parse(str(date_str))
            return parsed_date.strftime("%Y-%m-%d %H:%M:%S")
        except Exception as e:
            logger.error(f"æ—¥æœŸè§£æå¤±è´¥: {e}")
            return str(date_str)

    def _extract_metadata(self, response, config: Dict) -> Dict[str, Any]:
        """æå–å…ƒæ•°æ®"""
        metadata = {}

        try:
            # å“åº”å…ƒæ•°æ®
            if hasattr(response, "headers"):
                metadata["content_type"] = response.headers.get(
                    "Content-Type", b""
                ).decode("utf-8", errors="ignore")
                metadata["content_length"] = response.headers.get(
                    "Content-Length", b""
                ).decode("utf-8", errors="ignore")

            # æå–æ—¶é—´
            metadata["extraction_timestamp"] = self._get_current_time()

            # é…ç½®ä¿¡æ¯
            metadata["extraction_config"] = config.get("site_info", {}).get(
                "name", "unknown"
            )

        except Exception as e:
            logger.error(f"å…ƒæ•°æ®æå–å¤±è´¥: {e}")

        return metadata

    def _default_extract(self, response) -> Dict[str, Any]:
        """é»˜è®¤æå–æ–¹æ³•"""
        try:
            content = self._get_response_content(response)

            return {
                "url": getattr(response, "url", "unknown"),
                "status_code": getattr(response, "status", "unknown"),
                "content": content[:1000] if content else None,
                "extraction_time": self._get_current_time(),
            }
        except Exception as e:
            logger.error(f"é»˜è®¤æå–å¤±è´¥: {e}")
            return {
                "url": getattr(response, "url", "unknown"),
                "error": str(e),
                "extraction_time": self._get_current_time(),
            }

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime

        return datetime.now().isoformat()

    def _get_response_content(self, response) -> Optional[str]:
        """å®‰å…¨è·å–å“åº”å†…å®¹"""
        try:
            # æ£€æŸ¥Content-Type
            content_type = ""
            if hasattr(response, "headers"):
                content_type = response.headers.get("Content-Type", b"")
                if isinstance(content_type, bytes):
                    content_type = content_type.decode("utf-8", errors="ignore")
                content_type = content_type.lower()

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬ç±»å‹
            text_types = [
                "text/html",
                "text/plain",
                "text/xml",
                "application/xml",
                "application/xhtml+xml",
            ]
            is_text_type = any(t in content_type for t in text_types)

            if not is_text_type and content_type:
                logger.warning(f"éæ–‡æœ¬ç±»å‹å“åº”: {content_type}")
                return None

            # å°è¯•å¤šç§æ–¹å¼è·å–å†…å®¹
            if hasattr(response, "text"):
                try:
                    return response.text
                except Exception as e:
                    logger.warning(f"è·å–response.textå¤±è´¥: {e}")

            # å°è¯•ä»bodyè§£ç 
            if hasattr(response, "body"):
                try:
                    if isinstance(response.body, bytes):
                        # å°è¯•å¤šç§ç¼–ç 
                        for encoding in ["utf-8", "gbk", "gb2312", "latin1"]:
                            try:
                                return response.body.decode(encoding)
                            except UnicodeDecodeError:
                                continue
                    else:
                        return str(response.body)
                except Exception as e:
                    logger.warning(f"ä»bodyè§£ç å¤±è´¥: {e}")

            # æœ€åå°è¯•ç›´æ¥è½¬æ¢
            try:
                return str(response)
            except Exception as e:
                logger.error(f"æ— æ³•è·å–å“åº”å†…å®¹: {e}")
                return None

        except Exception as e:
            logger.error(f"è·å–å“åº”å†…å®¹å¼‚å¸¸: {e}")
            return None


class ExtractionConfigManager:
    """æå–é…ç½®ç®¡ç†å™¨"""

    def __init__(self):
        self.configs = {}
        self.config_dirs = ["config/extraction", "config/sites"]
        self.load_all_configs()

    def load_all_configs(self):
        """åŠ è½½æ‰€æœ‰é…ç½®æ–‡ä»¶"""
        from pathlib import Path

        for config_dir in self.config_dirs:
            config_path = Path(config_dir)
            if not config_path.exists():
                logger.warning(f"é…ç½®ç›®å½•ä¸å­˜åœ¨: {config_dir}")
                continue

            # åŠ è½½è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰yamlæ–‡ä»¶
            for config_file in config_path.glob("*.yaml"):
                try:
                    site_name = config_file.stem
                    with open(config_file, "r", encoding="utf-8") as f:
                        config = yaml.safe_load(f)

                    self.configs[site_name] = config
                    logger.info(f"âœ… åŠ è½½é…ç½®: {site_name} <- {config_file}")

                except Exception as e:
                    logger.error(f"âŒ åŠ è½½é…ç½®å¤±è´¥ {config_file}: {e}")

        logger.info(f"ğŸ“‹ æ€»å…±åŠ è½½äº† {len(self.configs)} ä¸ªç½‘ç«™é…ç½®")
        logger.info(f"ğŸ“‹ å¯ç”¨é…ç½®: {list(self.configs.keys())}")

    def get_config(self, site_name: str) -> Dict:
        """è·å–ç½‘ç«™é…ç½®"""
        if site_name in self.configs:
            return self.configs[site_name]

        # å°è¯•é‡æ–°åŠ è½½é…ç½®
        logger.warning(f"é…ç½® {site_name} ä¸å­˜åœ¨ï¼Œå°è¯•é‡æ–°åŠ è½½...")
        self.load_all_configs()

        return self.configs.get(site_name, {})

    def extract_data(self, response, site_name: str) -> Dict[str, Any]:
        """æå–æ•°æ®"""
        config = self.get_config(site_name)

        if not config:
            logger.warning(f"æœªæ‰¾åˆ°ç½‘ç«™é…ç½®: {site_name}ï¼Œä½¿ç”¨é»˜è®¤æå–")
            return self._default_extract(response)

        logger.info(f"ğŸ¯ ä½¿ç”¨é…ç½®æå–æ•°æ®: {site_name}")

        # åˆ›å»ºæå–å™¨å®ä¾‹
        extractor = ConfigurableExtractor()
        extractor.config = {site_name: config}

        return extractor.extract_data(response, site_name)

    def _default_extract(self, response) -> Dict[str, Any]:
        """é»˜è®¤æå–æ–¹æ³•"""
        try:
            # å®‰å…¨è·å–åŸºæœ¬ä¿¡æ¯
            url = getattr(response, "url", "unknown")
            status = getattr(response, "status", "unknown")

            # å°è¯•è·å–å†…å®¹
            content = None
            try:
                if hasattr(response, "text"):
                    content = response.text[:500]  # åªå–å‰500å­—ç¬¦
                elif hasattr(response, "body"):
                    content = response.body.decode("utf-8", errors="ignore")[:500]
            except:
                content = None

            return {
                "url": url,
                "status_code": status,
                "content": content,
                "extraction_time": self._get_current_time(),
                "extraction_method": "default",
            }
        except Exception as e:
            logger.error(f"é»˜è®¤æå–å¤±è´¥: {e}")
            return {
                "url": getattr(response, "url", "unknown"),
                "error": str(e),
                "extraction_time": self._get_current_time(),
                "extraction_method": "default_failed",
            }

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime

        return datetime.now().isoformat()
