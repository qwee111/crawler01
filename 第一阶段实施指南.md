# 第一阶段实施指南：基础框架搭建

## 1.1 开发环境搭建 (当前任务)

### 环境要求

#### 基础环境
```bash
# Python 版本
Python 3.9+

# 操作系统
Windows 10/11, Ubuntu 20.04+, macOS 11+

# 内存要求
最小 8GB RAM，推荐 16GB+

# 磁盘空间
最小 50GB 可用空间
```

#### 必需软件安装

1. **Python环境管理**
```bash
# 安装 Anaconda 或 Miniconda
# Windows: 下载安装包
# Linux/macOS:
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# 创建项目虚拟环境
conda create -n crawler_system python=3.9
conda activate crawler_system
```

2. **Git配置**
```bash
# 安装Git
# Windows: 下载Git for Windows
# Linux: sudo apt-get install git
# macOS: brew install git

# 配置Git
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
git config --global init.defaultBranch main
```

3. **IDE配置 (推荐VSCode)**
```bash
# 安装VSCode
# 下载地址: https://code.visualstudio.com/

# 必需插件
- Python
- Python Docstring Generator
- GitLens
- Docker
- YAML
- Markdown All in One
```

#### 核心依赖包安装

创建 `requirements.txt`:
```txt
# 爬虫框架
scrapy==2.11.0
scrapy-redis==0.7.3
scrapy-splash==0.8.0

# 浏览器自动化
selenium==4.15.0
webdriver-manager==4.0.1

# 数据处理
pandas==2.1.3
numpy==1.24.3
lxml==4.9.3
beautifulsoup4==4.12.2

# 数据库
pymongo==4.6.0
psycopg2-binary==2.9.9
redis==5.0.1
sqlalchemy==2.0.23

# 异步任务
celery==5.3.4
kombu==5.3.4

# 网络请求
requests==2.31.0
aiohttp==3.9.1
httpx==0.25.2

# 代理和反爬
fake-useragent==1.4.0
requests-html==0.10.0

# 监控和日志
prometheus-client==0.19.0
structlog==23.2.0
loguru==0.7.2

# 配置管理
pydantic==2.5.0
python-dotenv==1.0.0
pyyaml==6.0.1

# 测试
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0

# 代码质量
black==23.11.0
flake8==6.1.0
isort==5.12.0
pre-commit==3.6.0

# 开发工具
ipython==8.17.2
jupyter==1.0.0
```

安装依赖:
```bash
pip install -r requirements.txt
```

#### 代码质量工具配置

1. **创建 `.pre-commit-config.yaml`**
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-merge-conflict

  - repo: https://github.com/psf/black
    rev: 23.11.0
    hooks:
      - id: black
        language_version: python3

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
        args: [--max-line-length=88, --extend-ignore=E203]
```

2. **创建 `pyproject.toml`**
```toml
[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
known_first_party = ["crawler_system"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short --strict-markers"
markers = [
    "slow: marks tests as slow",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
]
```

3. **安装pre-commit钩子**
```bash
pre-commit install
```

#### Docker环境配置

1. **安装Docker**
```bash
# Windows: Docker Desktop
# Linux:
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# macOS:
brew install --cask docker
```

2. **创建开发用 `docker-compose.yml`**
```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

  mongodb:
    image: mongo:7
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongodb_data:/data/db

  postgres:
    image: postgres:15
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: crawler_db
      POSTGRES_USER: crawler_user
      POSTGRES_PASSWORD: crawler_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  redis_data:
  mongodb_data:
  postgres_data:
```

#### Git工作流规范

1. **分支策略**
```bash
# 主分支
main          # 生产环境代码
develop       # 开发环境代码

# 功能分支
feature/*     # 新功能开发
bugfix/*      # Bug修复
hotfix/*      # 紧急修复
release/*     # 发布准备
```

2. **提交信息规范 (Conventional Commits)**
```
<type>[optional scope]: <description>

[optional body]

[optional footer(s)]

类型:
feat: 新功能
fix: Bug修复
docs: 文档更新
style: 代码格式调整
refactor: 代码重构
test: 测试相关
chore: 构建过程或辅助工具的变动

示例:
feat(spider): add nhc.gov.cn spider
fix(proxy): handle proxy timeout error
docs(readme): update installation guide
```

3. **创建 `.gitignore`**
```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
logs/
data/
*.log
config/local_settings.py
.scrapy/
```

#### 项目初始化检查清单

- [ ] Python 3.9+ 环境配置完成
- [ ] 虚拟环境创建并激活
- [ ] 所有依赖包安装成功
- [ ] Git配置完成
- [ ] IDE配置完成，插件安装
- [ ] 代码质量工具配置完成
- [ ] pre-commit钩子安装
- [ ] Docker环境配置完成
- [ ] 开发数据库启动成功
- [ ] 项目Git仓库初始化
- [ ] 代码规范文档编写完成

#### 验证环境配置

运行以下命令验证环境:
```bash
# 检查Python版本
python --version

# 检查关键包
python -c "import scrapy; print('Scrapy:', scrapy.__version__)"
python -c "import redis; print('Redis client installed')"
python -c "import pymongo; print('MongoDB client installed')"

# 检查代码质量工具
black --version
flake8 --version
pre-commit --version

# 检查Docker
docker --version
docker-compose --version

# 启动开发环境
docker-compose up -d

# 检查服务状态
docker-compose ps
```

#### 下一步

环境搭建完成后，进入下一个任务：**项目结构初始化**

---

**注意事项**:
1. 确保所有团队成员使用相同的环境配置
2. 定期更新依赖包版本
3. 保持开发环境与生产环境的一致性
4. 及时备份重要配置文件
